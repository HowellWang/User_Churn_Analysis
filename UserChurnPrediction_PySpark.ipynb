{"cells":[{"cell_type":"markdown","source":["# User Churn Prediction"],"metadata":{}},{"cell_type":"markdown","source":["#### Submit By: Yuhao Wang"],"metadata":{}},{"cell_type":"markdown","source":["Original Data Source:\nhttps://www.sgi.com/tech/mlc/db/churn.all"],"metadata":{}},{"cell_type":"markdown","source":["#### Part 1\nLoad Data as Spark DataFrame"],"metadata":{}},{"cell_type":"code","source":["churn_data = sc.textFile(\"/FileStore/tables/tvcu6dws1495597580790/churn.all\")\nchurn_data.collect()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.types import *\nschema = StructType([ \\\n    StructField(\"state\", StringType(), True), \\\n    StructField(\"account_length\", DoubleType(), True), \\\n    StructField(\"area_code\", StringType(), True), \\\n    StructField(\"phone_number\", StringType(), True), \\\n    StructField(\"intl_plan\", StringType(), True), \\\n    StructField(\"voice_mail_plan\", StringType(), True), \\\n    StructField(\"number_vmail_messages\", DoubleType(), True), \\\n    StructField(\"total_day_minutes\", DoubleType(), True), \\\n    StructField(\"total_day_calls\", DoubleType(), True), \\\n    StructField(\"total_day_charge\", DoubleType(), True), \\\n    StructField(\"total_eve_minutes\", DoubleType(), True), \\\n    StructField(\"total_eve_calls\", DoubleType(), True), \\\n    StructField(\"total_eve_charge\", DoubleType(), True), \\\n    StructField(\"total_night_minutes\", DoubleType(), True), \\\n    StructField(\"total_night_calls\", DoubleType(), True), \\\n    StructField(\"total_night_charge\", DoubleType(), True), \\\n    StructField(\"total_intl_minutes\", DoubleType(), True), \\\n    StructField(\"total_intl_calls\", DoubleType(), True), \\\n    StructField(\"total_intl_charge\", DoubleType(), True), \\\n    StructField(\"number_customer_service_calls\", DoubleType(), True), \\\n    StructField(\"churned\", StringType(), True)])\n\nchurn_data2 = sqlContext.read.format('com.databricks.spark.csv').load('/FileStore/tables/tvcu6dws1495597580790/churn.all', schema = schema,header=\"true\")  "],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["#### Part 2\nModel training with Spark ML Pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\n\nreduced_numeric_cols = [\"account_length\", \"number_vmail_messages\", \"total_day_minutes\",\n                        \"total_day_calls\", \"total_day_charge\", \"total_eve_minutes\", \n                        \"total_eve_calls\", \"total_eve_charge\", \"total_night_minutes\",\n                        \"total_night_calls\", \"total_night_charge\", \"total_intl_minutes\", \n                        \"total_intl_calls\", \"total_intl_charge\",\"number_customer_service_calls\"]\n                        \nlabel_indexer = StringIndexer(inputCol = 'churned', outputCol = 'label')\nplan_indexer = StringIndexer(inputCol = 'intl_plan', outputCol = 'intl_plan_indexed')\nvoice_plan_indexer = StringIndexer(inputCol = 'voice_mail_plan', outputCol = 'voice_mail_plan_indexed')\n\nassembler = VectorAssembler(inputCols = ['intl_plan_indexed','voice_mail_plan_indexed']\n                            + reduced_numeric_cols, outputCol = 'features')\nclassifier = RandomForestClassifier(labelCol = 'label', featuresCol = 'features')\n\npipeline = Pipeline(stages=[plan_indexer, voice_plan_indexer, label_indexer, assembler, classifier])\n\n(train, test) = churn_data2.randomSplit([0.8, 0.2])\nmodel = pipeline.fit(train)\npredictions = model.transform(test)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#### Part 3\nResult Evaluation"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.evaluation import MulticlassMetrics\n\npredictionAndLabels = predictions.select(\"label\", \"prediction\").rdd#map(lambda lp: (lp.prediction, lp.label))\n\nmetrics = MulticlassMetrics(predictionAndLabels)\n\naccuracy = metrics.accuracy\nprecision = metrics.precision(1.0)\nrecall = metrics.recall(1.0)\nf1Score = metrics.fMeasure(1.0)\n\nprint(\"Summary Stats\")\nprint(\"Accuracy = %s\" % accuracy)\nprint(\"Precision = %s\" % precision)\nprint(\"Recall = %s\" % recall)\nprint(\"F1 Score = %s\" % f1Score)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nauroc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\nprint \"The AUROC is %s.\" % auroc"],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"name":"UserChurnPrediction_PySpark","notebookId":607450419319021},"nbformat":4,"nbformat_minor":0}
